{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised NLP\n",
    "- Requires pre-labelled dataset for training/testing\n",
    "- Mostly used for categorizing text\n",
    "- Use any supervised model that allows for categorical outcomes\n",
    "- **Bag of Words:** feature generation approach\n",
    "    - Count how many times each word appears for each sentence\n",
    "    - Use counts as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text cleaning function\n",
    "def text_cleaner(text):\n",
    "    # spaCy does not recognize '--', replace with blank string\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub('[\\[].*?[\\]]','',text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "#load and clean data\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "#chapter indicator is idiosyncratic\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "alice = re.sub(r'CHAPTER.*', '', alice)\n",
    "\n",
    "alice = text_cleaner(alice)\n",
    "persuasion = text_cleaner(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice 'without pictures or conversation?' So she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of gettin\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse cleaned novels\n",
    "nlp = spacy.load('en')\n",
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
       "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
       "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
       "3                                      (Oh, dear, !)  Carroll\n",
       "4                         (I, shall, be, late, !, ')  Carroll"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#group into sentences\n",
    "alice_sents = [[sent, 'Carroll'] for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, 'Austen'] for sent in persuasion_doc.sents]\n",
    "\n",
    "#combine sentences from novels into single df\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5318"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BoW, exclude stopwords & punctuation, use lemmas, 2000 most common words\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    #filter punct and stopwords\n",
    "    allwords = [token.lemma_ for token in text \n",
    "                if not token.is_punct and not token.is_stop]\n",
    "    \n",
    "    #return most common words\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "\n",
    "#creates a dataframe with features for each word in common word set\n",
    "#values are count of times word appears in each sentence\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    #set df and initialize counts\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    #process each row, counting word occurences\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        #convert sentence to lemmas & filter punct, stops, & uncommon words\n",
    "        words = [token.lemma_ for token in sentence\n",
    "                 if (not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words)]\n",
    "        \n",
    "        #populate row with word counts\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        #counter to make sure kernal isn't hanging\n",
    "        if i % 100 == 0:\n",
    "            print('processing row {}'.format(i))\n",
    "    \n",
    "    return df\n",
    "\n",
    "#set up bags\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "\n",
    "#combine bags to create set of unique words\n",
    "common_words = set(alicewords + persuasionwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mortification</th>\n",
       "      <th>violently</th>\n",
       "      <th>class</th>\n",
       "      <th>pause</th>\n",
       "      <th>apartment</th>\n",
       "      <th>domestic</th>\n",
       "      <th>legged</th>\n",
       "      <th>spread</th>\n",
       "      <th>correct</th>\n",
       "      <th>had</th>\n",
       "      <th>...</th>\n",
       "      <th>conqueror</th>\n",
       "      <th>upper</th>\n",
       "      <th>capital</th>\n",
       "      <th>roar</th>\n",
       "      <th>gather</th>\n",
       "      <th>calm</th>\n",
       "      <th>tunnel</th>\n",
       "      <th>tooth</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alice was beginning to get very tired of sitti...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>So she was considering in her own mind (as wel...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There was nothing so VERY remarkable in that; ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Oh dear!</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I shall be late!'</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3064 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mortification  violently  class  pause  apartment  domestic  legged  \\\n",
       "0              0          0      0      0          0         0       0   \n",
       "1              0          0      0      0          0         0       0   \n",
       "2              0          0      0      0          0         0       0   \n",
       "3              0          0      0      0          0         0       0   \n",
       "4              0          0      0      0          0         0       0   \n",
       "\n",
       "   spread  correct  had     ...       conqueror  upper  capital  roar  gather  \\\n",
       "0       0        0    0     ...               0      0        0     0       0   \n",
       "1       0        0    0     ...               0      0        0     0       0   \n",
       "2       0        0    0     ...               0      0        0     0       0   \n",
       "3       0        0    0     ...               0      0        0     0       0   \n",
       "4       0        0    0     ...               0      0        0     0       0   \n",
       "\n",
       "   calm  tunnel  tooth                                      text_sentence  \\\n",
       "0     0       0      0  Alice was beginning to get very tired of sitti...   \n",
       "1     0       0      0  So she was considering in her own mind (as wel...   \n",
       "2     0       0      0  There was nothing so VERY remarkable in that; ...   \n",
       "3     0       0      0                                           Oh dear!   \n",
       "4     0       0      0                                  I shall be late!'   \n",
       "\n",
       "   text_source  \n",
       "0      Carroll  \n",
       "1      Carroll  \n",
       "2      Carroll  \n",
       "3      Carroll  \n",
       "4      Carroll  \n",
       "\n",
       "[5 rows x 3064 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create df with features, this takes forever thankfully someone uploaded their completed file for me\n",
    "#word_counts = bow_features(sentences, common_words)\n",
    "\n",
    "word_counts = pd.read_csv('bow_features_alice_persuasion')\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9855799373040752\n",
      "test score: 0.8825187969924813\n",
      "0.6346969999999956 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "start_time = time.clock()\n",
    "train = rfc.fit(X_train, y_train)\n",
    "print('train score: {}'.format(rfc.score(X_train, y_train)))\n",
    "print('test score: {}'.format(rfc.score(X_test, y_test)))\n",
    "print('{} seconds'.format(time.clock() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:** overfitting, common problem with BoW and RF, try logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3190, 3062) (3190,)\n",
      "train score: 0.9579937304075236\n",
      "test score: 0.9158834586466166\n",
      "0.19104199999999594 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "start_time = time.clock()\n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('train score: {}'.format(lr.score(X_train, y_train)))\n",
    "print('test score: {}'.format(lr.score(X_test, y_test)))\n",
    "print('{} seconds'.format(time.clock() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.8846394984326019\n",
      "test score: 0.8735902255639098\n",
      "34.904721 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.clock()\n",
    "gbc = ensemble.GradientBoostingClassifier().fit(X_train, y_train)\n",
    "print('train score: {}'.format(gbc.score(X_train, y_train)))\n",
    "print('test score: {}'.format(gbc.score(X_test, y_test)))\n",
    "print('{} seconds'.format(time.clock() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same model, new inputs\n",
    "\n",
    "See if it can distinguish authors using a different sample of Austen's work, Emma. First need to load and process Emma the same way as earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean\n",
    "emma = gutenberg.raw('austen-emma.txt')\n",
    "emma = re.sub(r'VOLUME \\w+', '', emma)\n",
    "emma = re.sub(r'CHAPTER \\w+', '', emma)\n",
    "emma = text_cleaner(emma)\n",
    "print(emma[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse\n",
    "emma_doc = nlp(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group into sentences\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "emma_sents = [[sent, \"Austen\"] for sent in emma_doc.sents]\n",
    "\n",
    "#set to same length as alice (emma is longer)\n",
    "emma_sents = emma_sents[0:len(alice_sents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emma_sentences = pd.DataFrame(emma_sents)\n",
    "emma_bow = bow_features(emma_sentences, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with LR\n",
    "\n",
    "#combine emma and alice\n",
    "X_Emma_test = np.concatenate((\n",
    "    X_train[y_train[y_train=='Carroll'].index],\n",
    "    emma_bow.drop(['text_sentence','text_source'],1)),\n",
    "    axis=0)\n",
    "\n",
    "y_Emma_test = pd.concat(\n",
    "    [y_train[y_train=='Carroll'],\n",
    "     pd.Series(['Austen'] * emma_bow.shape[0])])\n",
    "\n",
    "print('test score: {}'.format(lr.score(X_Emma_test, y_Emma_test)))\n",
    "lr_Emma_predicted = lr.predict(X_Emma_test)\n",
    "pd.crosstab(y_Emma_test, lr_Emma_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 0\n",
    "Improve performance: try other models, adjust spacy params, features, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9156739811912226\n",
      "test score: 0.8947368421052632\n",
      "130.015896 seconds\n"
     ]
    }
   ],
   "source": [
    "#try gradient boosting I've had better results with\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "start_time = time.clock()\n",
    "xgb_clf = XGBClassifier(n_estimators=1000,\n",
    "                        learning_rate=0.05,).fit(X_train, y_train)\n",
    "\n",
    "#this takes too long\n",
    "#params = [{'max_depth':[2, 3, 5, 10],\n",
    "#           'learning_rate':[0.1, 0.05, 0.01],\n",
    "#           'subsample':[0.25, 0.5, 0.75, 1]}]\n",
    "\n",
    "#grid = GridSearchCV(estimator=xgb_clf, param_grid=params).fit(X_train, y_train)\n",
    "#print('params:', grid.best_params_)\n",
    "\n",
    "#xgb_clf = XGBClassifier(\n",
    "#    max_depth=grid.best_params_.get('max_depth'),\n",
    "#    learning_rate=grid.best_params_.get('learning_rate'),\n",
    "#    subsample=grid.best_params_.get('subsample')\n",
    "#).fit(X_train, y_train)\n",
    "\n",
    "print('train score: {}'.format(xgb_clf.score(X_train, y_train)))\n",
    "print('test score: {}'.format(xgb_clf.score(X_test, y_test)))\n",
    "print('{} seconds'.format(time.clock() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1\n",
    "Pull a new book and see if model can identify it vs alice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actus Primus. Scoena Prima. Thunder and Lightning. Enter three Witches. 1. When shall we three meet \n"
     ]
    }
   ],
   "source": [
    "mb = gutenberg.raw('shakespeare-macbeth.txt')\n",
    "\n",
    "mb = re.sub(r'VOLUME \\w+', '', mb)\n",
    "mb = re.sub(r'CHAPTER \\w+', '', mb)\n",
    "mb = text_cleaner(mb)\n",
    "print(mb[:100])\n",
    "\n",
    "mb_doc = nlp(mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_sents = [[sent, 'Shakesspeare'] for sent in mb_doc.sents]\n",
    "mb_sents = mb_sents[0:len(alice_sents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing row 0\n",
      "processing row 100\n",
      "processing row 200\n",
      "processing row 300\n",
      "processing row 400\n",
      "processing row 500\n",
      "processing row 600\n",
      "processing row 700\n",
      "processing row 800\n",
      "processing row 900\n",
      "processing row 1000\n",
      "processing row 1100\n",
      "processing row 1200\n",
      "processing row 1300\n",
      "processing row 1400\n",
      "processing row 1500\n",
      "processing row 1600\n"
     ]
    }
   ],
   "source": [
    "mb_sentences = pd.DataFrame(mb_sents)\n",
    "mb_bow = bow_features(mb_sentences, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: 0.9415584415584416\n",
      "test set: 0.8779940119760479\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Carroll</th>\n",
       "      <th>Shakesspeare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>510</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shakesspeare</th>\n",
       "      <td>26</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0         Carroll  Shakesspeare\n",
       "text_source                        \n",
       "Carroll           510           137\n",
       "Shakesspeare       26           663"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mb = mb_bow.drop(['text_sentence', 'text_source'], 1)\n",
    "y_mb = mb_bow.text_source\n",
    "\n",
    "alice_wc = word_counts[word_counts.text_source == 'Carroll']\n",
    "X_alice = alice_wc.drop(['text_sentence', 'text_source'], 1)\n",
    "y_alice = alice_wc.text_source\n",
    "\n",
    "X = pd.concat([X_mb, X_alice], 0)\n",
    "y = pd.concat([y_mb, y_alice], 0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "print('train set: {}'.format(lr.score(X_train, y_train)))\n",
    "print('test set: {}'.format(lr.score(X_test, y_test)))\n",
    "lr_mb_predicted = lr.predict(X_test)\n",
    "pd.crosstab(y_test, lr_mb_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
